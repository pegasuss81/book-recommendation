{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Model for Book Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings\n",
    "\n",
    "Word embedding is to build a NLP model that captures the semantic meanings of each word in a document. It creates word vectors and we can visualize the words in a vector space how are related to one another. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://nijianmo.github.io/amazon/index.html#subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#import json\n",
    "import ujson as json\n",
    "import gzip\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import base\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import RidgeCV, LinearRegression, SGDRegressor, Ridge\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot = pd.read_csv('data/df_merge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_tot[['reviewerID', 'asin', 'reviewText', 'overall', 'summary', 'unixReviewTime', 'description', 'title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3RZNH3OPW1XMB</td>\n",
       "      <td>000171287X</td>\n",
       "      <td>for getting your kid introduced to his/her ABC...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Great</td>\n",
       "      <td>1375401600</td>\n",
       "      <td>[\"In the B Book, the youngest child will be en...</td>\n",
       "      <td>The Berenstains' B Book (Bright &amp;amp; Early Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AZGXZ2UUK6X</td>\n",
       "      <td>000171287X</td>\n",
       "      <td>This Book is funny and is full of B words, lik...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>A celebration of B</td>\n",
       "      <td>1061078400</td>\n",
       "      <td>[\"In the B Book, the youngest child will be en...</td>\n",
       "      <td>The Berenstains' B Book (Bright &amp;amp; Early Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2K28JHMIY3XKZ</td>\n",
       "      <td>000171287X</td>\n",
       "      <td>A favorite Berenstain book of my children I wa...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Big B Believer</td>\n",
       "      <td>1001894400</td>\n",
       "      <td>[\"In the B Book, the youngest child will be en...</td>\n",
       "      <td>The Berenstains' B Book (Bright &amp;amp; Early Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1Z54EM24Y40LL</td>\n",
       "      <td>000171287X</td>\n",
       "      <td>This book is quite funny.  Especially when you...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Very funny book, sad ending though!</td>\n",
       "      <td>1108080000</td>\n",
       "      <td>[\"In the B Book, the youngest child will be en...</td>\n",
       "      <td>The Berenstains' B Book (Bright &amp;amp; Early Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A179R0UL62Q36Z</td>\n",
       "      <td>000171287X</td>\n",
       "      <td>Teaching the next generation to love books!  M...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Child's book</td>\n",
       "      <td>1345680000</td>\n",
       "      <td>[\"In the B Book, the youngest child will be en...</td>\n",
       "      <td>The Berenstains' B Book (Bright &amp;amp; Early Bo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  \\\n",
       "0  A3RZNH3OPW1XMB  000171287X   \n",
       "1     AZGXZ2UUK6X  000171287X   \n",
       "2  A2K28JHMIY3XKZ  000171287X   \n",
       "3  A1Z54EM24Y40LL  000171287X   \n",
       "4  A179R0UL62Q36Z  000171287X   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  for getting your kid introduced to his/her ABC...      5.0   \n",
       "1  This Book is funny and is full of B words, lik...      3.0   \n",
       "2  A favorite Berenstain book of my children I wa...      5.0   \n",
       "3  This book is quite funny.  Especially when you...      5.0   \n",
       "4  Teaching the next generation to love books!  M...      5.0   \n",
       "\n",
       "                               summary  unixReviewTime  \\\n",
       "0                                Great      1375401600   \n",
       "1                   A celebration of B      1061078400   \n",
       "2                       Big B Believer      1001894400   \n",
       "3  Very funny book, sad ending though!      1108080000   \n",
       "4                         Child's book      1345680000   \n",
       "\n",
       "                                         description  \\\n",
       "0  [\"In the B Book, the youngest child will be en...   \n",
       "1  [\"In the B Book, the youngest child will be en...   \n",
       "2  [\"In the B Book, the youngest child will be en...   \n",
       "3  [\"In the B Book, the youngest child will be en...   \n",
       "4  [\"In the B Book, the youngest child will be en...   \n",
       "\n",
       "                                               title  \n",
       "0  The Berenstains' B Book (Bright &amp; Early Bo...  \n",
       "1  The Berenstains' B Book (Bright &amp; Early Bo...  \n",
       "2  The Berenstains' B Book (Bright &amp; Early Bo...  \n",
       "3  The Berenstains' B Book (Bright &amp; Early Bo...  \n",
       "4  The Berenstains' B Book (Bright &amp; Early Bo...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_desc = df.groupby('asin', as_index=False, sort=False).last()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "We want to clean data a bit to keep meaningful text and make it easy to tokenize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-d184295911a9>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['cleaned_desc'] = df['description'].apply(remove_non_ascii)\n",
      "<ipython-input-10-d184295911a9>:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['cleaned_desc'] = df.cleaned_desc.apply(remove_html)\n"
     ]
    }
   ],
   "source": [
    "#Utitlity functions for removing ASCII characters, converting lower case, removing stop words, html and punctuation from description\n",
    "\n",
    "def remove_non_ascii(s):\n",
    "    return \"\".join(i for i in s if ord(i)<128)\n",
    "\n",
    "def make_lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    text = text.split()\n",
    "    text = [w for w in text if not w in STOP_WORDS]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "def remove_html(text):\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    return html_pattern.sub(r'', text)\n",
    "\n",
    "df['cleaned_desc'] = df['description'].apply(remove_non_ascii)\n",
    "#df['cleaned_desc'] = df.cleaned_desc.apply(make_lower_case)\n",
    "#df['cleaned_desc'] = df.cleaned_desc.apply(remove_stop_words)\n",
    "df['cleaned_desc'] = df.cleaned_desc.apply(remove_html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-cb6d36f0c3ae>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['reviewText'] = df['reviewText'].fillna('')\n"
     ]
    }
   ],
   "source": [
    "df['reviewText'] = df['reviewText'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-218b44b82874>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['cleaned_review'] = df['reviewText'].apply(remove_non_ascii)\n",
      "<ipython-input-12-218b44b82874>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['cleaned_review'] = df.cleaned_review.apply(remove_html)\n"
     ]
    }
   ],
   "source": [
    "df['cleaned_review'] = df['reviewText'].apply(remove_non_ascii)\n",
    "#df['cleaned_review'] = df.cleaned_review.apply(make_lower_case)\n",
    "#df['cleaned_review'] = df.cleaned_review.apply(remove_stop_words)\n",
    "df['cleaned_review'] = df.cleaned_review.apply(remove_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the tokenization, we use gensim's simple_preprocess here, which removes punctuations and change the words to lower cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I should break each description into sentences here. \n",
    "def process_review(review):\n",
    "    \"\"\"\n",
    "    Splits review into sentences, then sentences into tokens. Returns \n",
    "    nested list.\n",
    "    \"\"\"\n",
    "    words = [simple_preprocess(sentence, deacc=True) \n",
    "             for sentence in re.split('\\.|\\?|\\!', review)\n",
    "             if sentence]\n",
    "    return words\n",
    "\n",
    "# Flatten list to contain all sentences from all descriptions\n",
    "sentences_desc = [sentence for description in df.cleaned_desc for sentence in process_review(description)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten list to contain all sentences from all reviews\n",
    "sentences_review = [sentence for review in df.cleaned_review for sentence in process_review(review)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import PrettyPrinter\n",
    "\n",
    "# To format nested list\n",
    "pp = PrettyPrinter(indent=2)\n",
    "pp.pprint(sentences_desc[97:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(sentences_review[97:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Sentiment of Reviews\n",
    "\n",
    "I first want to check wheter I can extract sentiment from each review. This is also to indirectly check(?) the validity of the Word2Vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-8f1eb267e2f9>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['positive'] = df['overall'].apply(lambda x: 1 if x>=4 else 0)\n",
      "<ipython-input-15-8f1eb267e2f9>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['neutral'] = df['overall'].apply(lambda x: 1 if x<4 and x >=3 else 0)\n",
      "<ipython-input-15-8f1eb267e2f9>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['negative'] = df['overall'].apply(lambda x: 1 if x<=3 else 0)\n"
     ]
    }
   ],
   "source": [
    "# Read subset into DataFrame. Add sentiment column.\n",
    "df['positive'] = df['overall'].apply(lambda x: 1 if x>=4 else 0)\n",
    "df['neutral'] = df['overall'].apply(lambda x: 1 if x<4 and x >=3 else 0)\n",
    "df['negative'] = df['overall'].apply(lambda x: 1 if x<=3 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = df['cleaned_review'].apply(lambda r: len(simple_preprocess(r)))\n",
    "\n",
    "percentile = 80\n",
    "\n",
    "plt.hist(data, bins=range(0, 500, 25), density=True, color= \"skyblue\", lw=0.1)\n",
    "plt.axvline(np.percentile(data, percentile), \n",
    "            color='red', ls='--', label=f'{percentile}th percentile')\n",
    "plt.xlabel('number of tokens per sentence')\n",
    "plt.ylabel('% of all sentences')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roughly 200 tokens (words) are in one sentence for 80% of reviews. We will truncate the length of reviews accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding\n",
    "Now we want to train a word2vec model with the tokenized words in all reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_review = Word2Vec(sentences_review,\n",
    "               workers=4,   # Worker threads (=faster w/ multicore)\n",
    "               vector_size=30,    # Dimensionality of word vectors\n",
    "               window=5,    # Window size\n",
    "               min_count=3, # Ignore words with frequency lower than this\n",
    "               sample=1e-3) # Threshold for which higher-frequency \n",
    "                            # words are randomly downsampled\n",
    "\n",
    "w2v_review.save('review_children_books_w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_review = Word2Vec.load('review_children_books_w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of feature matrix: (396159, 100, 30)\n",
      "Shape of target vector: (396159, 1)\n"
     ]
    }
   ],
   "source": [
    "def vectorize_reviews(data, maxlen=100, embedding_dim=30):\n",
    "    \"\"\"\n",
    "    Tokenizes reviews, truncates the number of tokens if more than `maxlen`, \n",
    "    and vectorizes each token. Returns a three-dimensional array of shape\n",
    "    n reviews x `maxlen` x `embedding_dim`. \n",
    "    \"\"\"\n",
    "    # Create empty array\n",
    "    vectorized_data = np.zeros(shape=(len(data), maxlen, embedding_dim))\n",
    "    \n",
    "    for row, review in enumerate(data):\n",
    "        # Preprocess each review\n",
    "        tokens = simple_preprocess(review)\n",
    "        \n",
    "        # Truncate long reviews\n",
    "        if len(tokens) > maxlen:\n",
    "            tokens = tokens[:maxlen]\n",
    "        \n",
    "        # Get vector for each token in review\n",
    "        for col, token in enumerate(tokens):\n",
    "            try:\n",
    "                word_vector = w2v_review.wv[token]\n",
    "                # Add vector to array\n",
    "                vectorized_data[row, col] = word_vector[:embedding_dim]\n",
    "            except KeyError:\n",
    "                pass\n",
    "    \n",
    "    return vectorized_data\n",
    "\n",
    "maxlen = 100        # Our predetermined limit\n",
    "embedding_dim = 30 # The first 30 values in our w2v vectors\n",
    "\n",
    "X = vectorize_reviews(df.cleaned_review, maxlen, embedding_dim)\n",
    "y = df.positive.values.reshape(-1,1)\n",
    "\n",
    "print('Shape of feature matrix:', X.shape)\n",
    "print('Shape of target vector:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data with GRU (Gated Recurrent Units) model\n",
    "\n",
    "GRU is a part of a specific model of RNN (Recurrent Neural Network), which is in comparison effective in retaining long term memory and also efficient and fast in operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 100, 128)          61440     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100, 128)          0         \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 64)                37248     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,753\n",
      "Trainable params: 98,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "         \n",
    "maxlen=100\n",
    "embedding_dim=30\n",
    "\n",
    "gru_model = Sequential([\n",
    "    GRU(128, return_sequences=True, input_shape=(maxlen, embedding_dim)),\n",
    "    Dropout(0.25),\n",
    "    GRU(64),\n",
    "    Dropout(0.25),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "gru_model.save(\"gru_weights_review_maxlen_100_exbeddingDim_30.h5\")\n",
    "#gru_model.save(\"gru_weights_review_maxlen_200_exbeddingDim_30.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model.load_weights(\"gru_weights_review_maxlen_100_exbeddingDim_30.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating our GRU model for sentiment extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model.compile(loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'], \n",
    "                  optimizer='adam')\n",
    "\n",
    "history = gru_model.fit(X_train, y_train, epochs=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive\n",
    "my_pos_review = \"\"\"this book is amazing\"\"\"\n",
    "\n",
    "# Negative\n",
    "my_neg_review = \"\"\"boring, does not capture attention\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize reviews\n",
    "test_vec = vectorize_reviews([my_pos_review, my_neg_review])\n",
    "\n",
    "# Generate predictions\n",
    "prediction = gru_model.predict(test_vec)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can predict the sentiment of each review with the accuracy of ~76%. Now let's explore how words are symantically related in a vector space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Description\n",
    "\n",
    "First, let's train the descriptions with Word2Vec and explore how each word maps in 2D space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_desc = Word2Vec(sentences_desc,\n",
    "               workers=4,   # Worker threads (=faster w/ multicore)\n",
    "               vector_size=30,    # Dimensionality of word vectors\n",
    "               window=5,    # Window size\n",
    "               min_count=3, # Ignore words with frequency lower than this\n",
    "               sample=1e-3) # Threshold for which higher-frequency \n",
    "                            # words are randomly downsampled\n",
    "\n",
    "w2v_desc.save('description_books_w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w2v_desc = Word2Vec.load('description_books_w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect vectors for n most common words in vocabulary\n",
    "n = 500\n",
    "vocabulary = [word for word in list(w2v_desc.wv.index_to_key) #[word for word in w2v.wv.vocab.keys() \n",
    "              if word not in STOP_WORDS][:n]\n",
    "#vocabulary = sorted(vocabulary, key=lambda x: -w2v.wv.index_to_key[x].count)[:n]\n",
    "#vocabulary = sorted(vocabulary, key=lambda x: -w2v.wv.vocab[x].count)[:n]\n",
    "vectors = w2v_desc.wv[vocabulary]\n",
    "\n",
    "# Reduce vector dimensionality from 30 to 2\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "vectors_t = pca.fit_transform(vectors)\n",
    "\n",
    "# Put transformed vectors into DataFrame\n",
    "vocab_df = pd.DataFrame(vectors_t, columns=['x', 'y']).assign(word=vocabulary)\n",
    "\n",
    "# Print head\n",
    "vocab_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.models import BoxZoomTool, ColumnDataSource, HoverTool, ResetTool\n",
    "from bokeh.models.annotations import Span, Label\n",
    "from bokeh.plotting import figure\n",
    "output_notebook()\n",
    "\n",
    "# Helper function\n",
    "def get_coords(word):\n",
    "    \"\"\"Given a word from `vocab_df`, returns tuple with x, y coordinates.\"\"\"\n",
    "    coords = vocab_df[vocab_df['word'] == word][['x', 'y']]\n",
    "    return list(coords.itertuples(name=None, index=False))[0]\n",
    "\n",
    "# Create plot\n",
    "p = figure(plot_width=700, \n",
    "           plot_height=400,\n",
    "           tools=[HoverTool(tooltips='@word'), BoxZoomTool(), ResetTool()],\n",
    "           title='Book Description Vocabulary')\n",
    "\n",
    "# Add vocabulary\n",
    "source = ColumnDataSource(vocab_df)\n",
    "p.circle('x', 'y', source=source, size=5, \n",
    "         fill_color='blue', fill_alpha=0.3, \n",
    "         hover_fill_color='yellow')\n",
    "\n",
    "# Add verticle and horizontal lines\n",
    "line_x, line_y = get_coords('story')\n",
    "\n",
    "vline = Span(location=line_x, dimension='height', \n",
    "             line_dash='dashed', line_color='red')\n",
    "p.add_layout(vline)\n",
    "\n",
    "hline = Span(location=line_y, dimension='width', \n",
    "             line_dash='dashed', line_color='red')\n",
    "p.add_layout(hline)\n",
    "\n",
    "# Display plot\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_rooted(x):\n",
    "    \"\"\"Helper function for `cosine_similarity()`\"\"\"\n",
    "    return sum([a * a for a in x])**0.5\n",
    "  \n",
    "# def cosine_similarity(word1, word2):\n",
    "#     \"\"\"\n",
    "#     Given two words in `vocab_df` DataFrame, returns cosine similarity of word\n",
    "#     vectors.\n",
    "#     \"\"\"\n",
    "#     vec1, vec2 = get_coords(word1), get_coords(word2)\n",
    "#     numerator = sum(a * b for a, b in zip(vec1, vec2))\n",
    "#     denominator = square_rooted(vec1) * square_rooted(vec2)\n",
    "#     return numerator/denominator\n",
    "\n",
    "print('Cosine similarity for STORY and CHARACTERS  (PCA):', \n",
    "      cosine_similarity('story', 'characters'))\n",
    "\n",
    "print('Cosine similarity for STORY and SHORT (PCA):', \n",
    "      cosine_similarity('story', 'short'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cosine similarity for STORY and CHARACTERS  (FULL W2V):',\n",
    "      w2v_desc.wv.similarity('story', 'characters'))\n",
    "\n",
    "print('Cosine similarity for STORY and SHORT (FULL W2V):',\n",
    "      w2v_desc.wv.similarity('story', 'short'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_desc.wv.most_similar('problem')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize the Text Reviews by Each Book\n",
    "\n",
    "So far, we created word vectors for each word in reviews and in descriptions. Now we want to combine these vectors to get one vector for each book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.groupby('asin')['reviewText'].apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000171287X</td>\n",
       "      <td>A2GLWCPW4DI9DX</td>\n",
       "      <td>I remember this beloved book from when I was a...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The classic! A positive, fun lift for any time...</td>\n",
       "      <td>1380931200</td>\n",
       "      <td>[\"In the B Book, the youngest child will be en...</td>\n",
       "      <td>The Berenstains' B Book (Bright &amp;amp; Early Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001714538</td>\n",
       "      <td>A6HXFDIC7DVTC</td>\n",
       "      <td>Another one of the Berenstain Bears Early Read...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Fun book</td>\n",
       "      <td>1238716800</td>\n",
       "      <td>['By Stan Berenstain, Illustrated by Stan Bere...</td>\n",
       "      <td>The Berenstain Bears On the Moon (Bright and E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0006479286</td>\n",
       "      <td>A1CCEOOK2M6BI0</td>\n",
       "      <td>The delivry was fast.  The book was fantastic ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>good book</td>\n",
       "      <td>1342828800</td>\n",
       "      <td>[\"'STEPHEN KING MEETING WITH RUTH RENDELL' - F...</td>\n",
       "      <td>On the Edge of Darkness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0006485944</td>\n",
       "      <td>A3532D080M9CL8</td>\n",
       "      <td>I'm not sure what drew me to this book, but up...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>An unexpected surprise!</td>\n",
       "      <td>1355097600</td>\n",
       "      <td>['Grade 6-9-In a bone-dry summer during the Gr...</td>\n",
       "      <td>Dust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0006547192</td>\n",
       "      <td>AUTBHG6070SL4</td>\n",
       "      <td>Lessing's criticism of the twentieth century i...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Like the series, but ...</td>\n",
       "      <td>1075075200</td>\n",
       "      <td>[\"'Magnificent...an astounding book that sets ...</td>\n",
       "      <td>Shikasta : Re-Colonised Planet 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin      reviewerID  \\\n",
       "0  000171287X  A2GLWCPW4DI9DX   \n",
       "1  0001714538   A6HXFDIC7DVTC   \n",
       "2  0006479286  A1CCEOOK2M6BI0   \n",
       "3  0006485944  A3532D080M9CL8   \n",
       "4  0006547192   AUTBHG6070SL4   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  I remember this beloved book from when I was a...      5.0   \n",
       "1  Another one of the Berenstain Bears Early Read...      4.0   \n",
       "2  The delivry was fast.  The book was fantastic ...      5.0   \n",
       "3  I'm not sure what drew me to this book, but up...      5.0   \n",
       "4  Lessing's criticism of the twentieth century i...      3.0   \n",
       "\n",
       "                                             summary  unixReviewTime  \\\n",
       "0  The classic! A positive, fun lift for any time...      1380931200   \n",
       "1                                           Fun book      1238716800   \n",
       "2                                          good book      1342828800   \n",
       "3                            An unexpected surprise!      1355097600   \n",
       "4                           Like the series, but ...      1075075200   \n",
       "\n",
       "                                         description  \\\n",
       "0  [\"In the B Book, the youngest child will be en...   \n",
       "1  ['By Stan Berenstain, Illustrated by Stan Bere...   \n",
       "2  [\"'STEPHEN KING MEETING WITH RUTH RENDELL' - F...   \n",
       "3  ['Grade 6-9-In a bone-dry summer during the Gr...   \n",
       "4  [\"'Magnificent...an astounding book that sets ...   \n",
       "\n",
       "                                               title  \n",
       "0  The Berenstains' B Book (Bright &amp; Early Bo...  \n",
       "1  The Berenstain Bears On the Moon (Bright and E...  \n",
       "2                            On the Edge of Darkness  \n",
       "3                                               Dust  \n",
       "4                   Shikasta : Re-Colonised Planet 5  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_review = df.groupby('asin')['reviewText'].apply(list).to_frame()\n",
    "df_merge_review = pd.merge(df_merge_review, df_unique_desc[['asin', 'description']], how='inner', on='asin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the average rating for each book\n",
    "df_merge_review = pd.merge(df_merge_review, df.groupby('asin')['overall'].mean().to_frame(), how='inner', on='asin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_review['reviewText'] = df_merge_review['reviewText'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_review['description'] = df_merge_review['description'].apply(lambda x: x[1:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_review.to_csv('data/df_merge_review.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_review = pd.read_csv('data/df_merge_review_title.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_review_each_book = Word2Vec(sentences_review,\n",
    "               workers=4,   # Worker threads (=faster w/ multicore)\n",
    "               vector_size=30,    # Dimensionality of word vectors\n",
    "               window=5,    # Window size\n",
    "               min_count=3, # Ignore words with frequency lower than this\n",
    "               sample=1e-3) # Threshold for which higher-frequency \n",
    "                            # words are randomly downsampled\n",
    "\n",
    "w2v_review_each_book.save('combined_review_children_books_w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of feature matrix: (21951, 100, 30)\n"
     ]
    }
   ],
   "source": [
    "def vectorize_combined_reviews(data, maxlen=100, embedding_dim=30):\n",
    "    \"\"\"\n",
    "    Tokenizes reviews, truncates the number of tokens if more than `maxlen`, \n",
    "    and vectorizes each token. Returns a three-dimensional array of shape\n",
    "    n reviews x `maxlen` x `embedding_dim`. \n",
    "    \"\"\"\n",
    "    # Create empty array\n",
    "    vectorized_data = np.zeros(shape=(len(data), maxlen, embedding_dim))\n",
    "    \n",
    "    for row, review in enumerate(data):\n",
    "        # Preprocess each review\n",
    "        tokens = simple_preprocess(review)\n",
    "        \n",
    "        # Truncate long reviews\n",
    "        if len(tokens) > maxlen:\n",
    "            tokens = tokens[:maxlen]\n",
    "        \n",
    "        # Get vector for each token in review\n",
    "        for col, token in enumerate(tokens):\n",
    "            try:\n",
    "                word_vector = w2v_review_each_book.wv[token]\n",
    "                # Add vector to array\n",
    "                vectorized_data[row, col] = word_vector[:embedding_dim]\n",
    "            except KeyError:\n",
    "                pass\n",
    "    \n",
    "    return vectorized_data\n",
    "\n",
    "maxlen = 100        # Our predetermined limit\n",
    "embedding_dim = 30 # The first 30 values in our w2v vectors\n",
    "\n",
    "X = vectorize_combined_reviews(df_merge_review.reviewText, maxlen, embedding_dim)\n",
    "\n",
    "print('Shape of feature matrix:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean of vectors for each book\n",
    "average_vec = []\n",
    "\n",
    "for i in range(len(X)):\n",
    "    average = np.mean(X[i], axis=0)\n",
    "    average_vec.append(average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.74961967,  0.20854406,  1.36508307,  0.89281046, -0.25358444,\n",
       "       -0.9230866 , -0.99924648,  0.56569635, -0.18658994,  0.96578283,\n",
       "       -0.31777611, -1.29112451,  1.10610055,  0.12416214,  1.09634157,\n",
       "        0.72582806, -1.00239424,  1.56614611, -0.008306  ,  0.90678533,\n",
       "       -0.09713234,  0.56218428,  0.28531339,  1.62575801,  0.45146213,\n",
       "        0.05547156,  0.16414765,  1.37443876, -0.68329014,  0.84266695])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_vec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21951"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(average_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-7.233059</td>\n",
       "      <td>-3.829195</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.277613</td>\n",
       "      <td>-6.684560</td>\n",
       "      <td>read</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9.003922</td>\n",
       "      <td>-0.692505</td>\n",
       "      <td>story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.804716</td>\n",
       "      <td>-6.337422</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-7.259346</td>\n",
       "      <td>-4.087783</td>\n",
       "      <td>books</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y   word\n",
       "0 -7.233059 -3.829195   book\n",
       "1  4.277613 -6.684560   read\n",
       "2 -9.003922 -0.692505  story\n",
       "3  4.804716 -6.337422   like\n",
       "4 -7.259346 -4.087783  books"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect vectors for n most common words in vocabulary\n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n",
    "# Collect vectors for n most common words in vocabulary\n",
    "n = 500\n",
    "vocabulary_review = [word for word in list(w2v_review_each_book.wv.index_to_key) #[word for word in w2v.wv.vocab.keys() \n",
    "              if word not in STOP_WORDS][:n]\n",
    "vocabulary_review = [book for book in list(average_vec)]\n",
    "#vocabulary = sorted(vocabulary, key=lambda x: -w2v.wv.index_to_key[x].count)[:n]\n",
    "#vocabulary = sorted(vocabulary, key=lambda x: -w2v.wv.vocab[x].count)[:n]\n",
    "vectors = w2v_review_each_book.wv[vocabulary_review]\n",
    "\n",
    "# Reduce vector dimensionality from 30 to 2\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "vectors_t = pca.fit_transform(vectors)\n",
    "\n",
    "# Put transformed vectors into DataFrame\n",
    "vocab_df_review = pd.DataFrame(vectors_t, columns=['x', 'y']).assign(word=vocabulary_review)\n",
    "\n",
    "# Print head\n",
    "vocab_df_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.0580502 , -2.1748219 ,  6.211654  ,  0.8764504 ,  3.1389542 ,\n",
       "       -0.7404901 , -0.89133596,  2.6319623 ,  1.5758806 ,  1.8861952 ,\n",
       "        1.1342572 , -6.617124  ,  0.28347853, -1.875129  , -0.7811584 ,\n",
       "        4.0745735 , -6.147056  ,  2.532177  , -0.9055427 , -1.2474566 ,\n",
       "       -0.90625554,  2.8521867 ,  3.810676  ,  1.9543322 ,  0.34781027,\n",
       "       -0.752659  ,  4.9458404 ,  2.6059577 ,  1.5508252 ,  2.9407253 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_review_each_book.wv['story']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommending the Top 5 similar books\n",
    "\n",
    "def recommendations_wv(title):\n",
    "    # finding cosine similarity for the vectors\n",
    "    cosine_similarities = cosine_similarity(average_vec, average_vec)\n",
    "\n",
    "    books = df_merge_review[['title']]\n",
    "    #Reverse mapping of the index\n",
    "    indices = pd.Series(df_merge_review.index, index = df_merge_review['title']).drop_duplicates()\n",
    "         \n",
    "    idx = indices[title]\n",
    "    sim_scores = list(enumerate(cosine_similarities[idx]))\n",
    "    sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse = True)\n",
    "    sim_scores = sim_scores[1:6]\n",
    "    book_indices = [i[0] for i in sim_scores]\n",
    "    recommend = books.iloc[book_indices]\n",
    "    for index, row in recommend.iterrows():\n",
    "        print(row['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kids Go!\n",
      "Boats: Speeding! Sailing! Cruising!\n",
      "Cats' Night Out (Paula Wiseman Books)\n",
      "Ballpark\n",
      "One Little Match\n"
     ]
    }
   ],
   "source": [
    "recommendations_wv('The Snowy Day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\": \"T2yuo9Oe71Cz/I4X9Ac5+gpEa5a8PpJCDlqKYO0CfAuEszu1JrXLl8YugMqYe3sM\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\": \"98GDGJ0kOMCUMUePhksaQ/GYgB3+NH9h996V88sh3aOiUNX3N+fLXAtry6xctSZ6\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\": \"89bArO+nlbP3sgakeHjCo1JYxYR5wufVgA3IbUvDY+K7w4zyxJqssu7wVnfeKCq8\"};\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\": \"T2yuo9Oe71Cz/I4X9Ac5+gpEa5a8PpJCDlqKYO0CfAuEszu1JrXLl8YugMqYe3sM\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\": \"98GDGJ0kOMCUMUePhksaQ/GYgB3+NH9h996V88sh3aOiUNX3N+fLXAtry6xctSZ6\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\": \"89bArO+nlbP3sgakeHjCo1JYxYR5wufVgA3IbUvDY+K7w4zyxJqssu7wVnfeKCq8\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"699d0483-4aee-4324-9d56-42536c8324fa\" data-root-id=\"1005\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"4239e8ec-8f07-4135-80c0-bda5ee78c12d\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1016\"}],\"center\":[{\"id\":\"1019\"},{\"id\":\"1023\"},{\"id\":\"1036\"},{\"id\":\"1037\"}],\"left\":[{\"id\":\"1020\"}],\"plot_height\":400,\"plot_width\":700,\"renderers\":[{\"id\":\"1034\"}],\"title\":{\"id\":\"1006\"},\"toolbar\":{\"id\":\"1025\"},\"x_range\":{\"id\":\"1008\"},\"x_scale\":{\"id\":\"1012\"},\"y_range\":{\"id\":\"1010\"},\"y_scale\":{\"id\":\"1014\"}},\"id\":\"1005\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"source\":{\"id\":\"1029\"}},\"id\":\"1035\",\"type\":\"CDSView\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"blue\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":5},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1032\",\"type\":\"Circle\"},{\"attributes\":{\"formatter\":{\"id\":\"1040\"},\"ticker\":{\"id\":\"1017\"}},\"id\":\"1016\",\"type\":\"LinearAxis\"},{\"attributes\":{\"callback\":null,\"tooltips\":\"@word\"},\"id\":\"1002\",\"type\":\"HoverTool\"},{\"attributes\":{},\"id\":\"1040\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"overlay\":{\"id\":\"1024\"}},\"id\":\"1003\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"dimension\":\"height\",\"line_color\":\"red\",\"line_dash\":[6],\"location\":-9.003921508789062},\"id\":\"1036\",\"type\":\"Span\"},{\"attributes\":{\"line_color\":\"red\",\"line_dash\":[6],\"location\":-0.6925045251846313},\"id\":\"1037\",\"type\":\"Span\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1024\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"text\":\"Book Reviews Vocabulary\"},\"id\":\"1006\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1042\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.3},\"fill_color\":{\"value\":\"blue\"},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":5},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1031\",\"type\":\"Circle\"},{\"attributes\":{\"formatter\":{\"id\":\"1042\"},\"ticker\":{\"id\":\"1021\"}},\"id\":\"1020\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1008\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1014\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1010\",\"type\":\"DataRange1d\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.3},\"fill_color\":{\"value\":\"yellow\"},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":5},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1033\",\"type\":\"Circle\"},{\"attributes\":{},\"id\":\"1017\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1012\",\"type\":\"LinearScale\"},{\"attributes\":{\"axis\":{\"id\":\"1016\"},\"ticker\":null},\"id\":\"1019\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1043\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"data_source\":{\"id\":\"1029\"},\"glyph\":{\"id\":\"1031\"},\"hover_glyph\":{\"id\":\"1033\"},\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1032\"},\"selection_glyph\":null,\"view\":{\"id\":\"1035\"}},\"id\":\"1034\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1044\",\"type\":\"Selection\"},{\"attributes\":{\"data\":{\"index\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499],\"word\":[\"book\",\"read\",\"story\",\"like\",\"books\",\"children\",\"love\",\"great\",\"good\",\"time\",\"reading\",\"little\",\"characters\",\"life\",\"way\",\"series\",\"child\",\"old\",\"author\",\"think\",\"kids\",\"young\",\"know\",\"new\",\"world\",\"year\",\"people\",\"find\",\"don\",\"things\",\"family\",\"fun\",\"loved\",\"end\",\"character\",\"school\",\"written\",\"want\",\"novel\",\"stories\",\"recommend\",\"found\",\"didn\",\"going\",\"best\",\"enjoyed\",\"help\",\"different\",\"illustrations\",\"lot\",\"girl\",\"parents\",\"interesting\",\"ve\",\"years\",\"work\",\"reader\",\"bit\",\"day\",\"thought\",\"page\",\"writing\",\"daughter\",\"readers\",\"better\",\"enjoy\",\"right\",\"review\",\"feel\",\"doesn\",\"makes\",\"plot\",\"pages\",\"friends\",\"wonderful\",\"mother\",\"son\",\"real\",\"long\",\"got\",\"come\",\"look\",\"liked\",\"times\",\"easy\",\"thing\",\"loves\",\"sure\",\"home\",\"looking\",\"boy\",\"age\",\"hard\",\"words\",\"god\",\"away\",\"father\",\"learn\",\"need\",\"use\",\"favorite\",\"pictures\",\"ll\",\"highly\",\"especially\",\"felt\",\"bad\",\"perfect\",\"definitely\",\"big\",\"friend\",\"girls\",\"understand\",\"place\",\"man\",\"having\",\"point\",\"nice\",\"actually\",\"beautiful\",\"fact\",\"cute\",\"main\",\"short\",\"history\",\"isn\",\"able\",\"set\",\"kind\",\"start\",\"ending\",\"true\",\"mystery\",\"takes\",\"tale\",\"lives\",\"comes\",\"second\",\"gets\",\"pretty\",\"person\",\"wasn\",\"far\",\"heart\",\"action\",\"simple\",\"adult\",\"high\",\"wanted\",\"said\",\"trying\",\"adventure\",\"job\",\"left\",\"information\",\"hope\",\"getting\",\"bought\",\"small\",\"wait\",\"let\",\"tell\",\"told\",\"adults\",\"night\",\"excellent\",\"stars\",\"goes\",\"believe\",\"mind\",\"baby\",\"course\",\"house\",\"copy\",\"beginning\",\"making\",\"amazing\",\"wants\",\"idea\",\"funny\",\"live\",\"quot\",\"boys\",\"cover\",\"picture\",\"probably\",\"happy\",\"important\",\"older\",\"try\",\"chapter\",\"couldn\",\"style\",\"sense\",\"middle\",\"past\",\"started\",\"overall\",\"given\",\"instead\",\"maybe\",\"won\",\"line\",\"gift\",\"younger\",\"kid\",\"learning\",\"forward\",\"came\",\"fiction\",\"ones\",\"worth\",\"buy\",\"fantasy\",\"attention\",\"sister\",\"kept\",\"death\",\"gives\",\"received\",\"ages\",\"care\",\"grade\",\"text\",\"free\",\"finds\",\"lost\",\"truly\",\"magic\",\"human\",\"woman\",\"interest\",\"strong\",\"wish\",\"animals\",\"romance\",\"sweet\",\"library\",\"war\",\"write\",\"mom\",\"special\",\"bible\",\"soon\",\"finally\",\"fan\",\"brother\",\"follow\",\"gave\",\"took\",\"christmas\",\"group\",\"tells\",\"word\",\"dog\",\"fast\",\"questions\",\"problem\",\"experience\",\"reacher\",\"recommended\",\"change\",\"art\",\"days\",\"self\",\"novels\",\"knows\",\"relationship\",\"interested\",\"wrong\",\"authors\",\"message\",\"coming\",\"star\",\"jack\",\"shows\",\"case\",\"works\",\"town\",\"future\",\"living\",\"mr\",\"ways\",\"play\",\"simply\",\"went\",\"women\",\"knew\",\"students\",\"parent\",\"dark\",\"honest\",\"needs\",\"turn\",\"happen\",\"unique\",\"early\",\"entertaining\",\"completely\",\"reason\",\"etc\",\"issues\",\"difficult\",\"later\",\"parts\",\"absolutely\",\"happened\",\"half\",\"american\",\"stop\",\"order\",\"level\",\"lots\",\"matter\",\"original\",\"happens\",\"mean\",\"quickly\",\"thinking\",\"turns\",\"light\",\"seen\",\"money\",\"based\",\"eyes\",\"yes\",\"evil\",\"head\",\"black\",\"couple\",\"called\",\"says\",\"language\",\"journey\",\"face\",\"example\",\"rest\",\"certainly\",\"remember\",\"details\",\"teacher\",\"entire\",\"starts\",\"events\",\"enjoyable\",\"class\",\"deal\",\"th\",\"easily\",\"giving\",\"humor\",\"king\",\"problems\",\"hand\",\"writer\",\"reviews\",\"ago\",\"feeling\",\"today\",\"title\",\"teach\",\"begins\",\"ideas\",\"view\",\"movie\",\"disappointed\",\"finished\",\"share\",\"learned\",\"named\",\"personal\",\"talk\",\"clear\",\"chapters\",\"food\",\"quick\",\"filled\",\"adventures\",\"including\",\"known\",\"guy\",\"save\",\"add\",\"exciting\",\"collection\",\"leave\",\"historical\",\"husband\",\"white\",\"type\",\"colorful\",\"fantastic\",\"bring\",\"men\",\"secret\",\"awesome\",\"feels\",\"city\",\"taken\",\"dead\",\"run\",\"power\",\"ends\",\"glad\",\"science\",\"pick\",\"ms\",\"version\",\"summer\",\"taking\",\"cat\",\"keeps\",\"ya\",\"telling\",\"lesson\",\"created\",\"illustrated\",\"wouldn\",\"setting\",\"dad\",\"likes\",\"working\",\"addition\",\"color\",\"sort\",\"sad\",\"detail\",\"fans\",\"exactly\",\"saw\",\"christian\",\"teen\",\"totally\",\"hands\",\"needed\",\"engaging\",\"country\",\"close\",\"despite\",\"inside\",\"meet\",\"scenes\",\"open\",\"truth\",\"expect\",\"feelings\",\"figure\",\"earth\",\"subject\",\"huge\",\"lessons\",\"magical\",\"imagination\",\"beautifully\",\"means\",\"present\",\"aren\",\"list\",\"classic\",\"fall\",\"wife\",\"excited\",\"trouble\",\"strange\",\"positive\",\"friendship\",\"reads\",\"fairy\",\"opinion\",\"finding\",\"months\",\"particularly\",\"hero\",\"relate\",\"childhood\",\"certain\",\"helps\",\"twists\",\"voice\",\"seeing\",\"heard\",\"sequel\",\"finish\",\"large\",\"princess\",\"chance\",\"oh\",\"wonder\",\"usually\",\"teens\",\"number\",\"brought\",\"harry\",\"game\",\"development\",\"society\",\"tales\",\"turned\",\"body\",\"stuff\"],\"x\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[500]},\"y\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[500]}},\"selected\":{\"id\":\"1044\"},\"selection_policy\":{\"id\":\"1043\"}},\"id\":\"1029\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"axis\":{\"id\":\"1020\"},\"dimension\":1,\"ticker\":null},\"id\":\"1023\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1004\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1021\",\"type\":\"BasicTicker\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1002\"},{\"id\":\"1003\"},{\"id\":\"1004\"}]},\"id\":\"1025\",\"type\":\"Toolbar\"}],\"root_ids\":[\"1005\"]},\"title\":\"Bokeh Application\",\"version\":\"2.2.3\"}};\n",
       "  var render_items = [{\"docid\":\"4239e8ec-8f07-4135-80c0-bda5ee78c12d\",\"root_ids\":[\"1005\"],\"roots\":{\"1005\":\"699d0483-4aee-4324-9d56-42536c8324fa\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1005"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.models import BoxZoomTool, ColumnDataSource, HoverTool, ResetTool\n",
    "from bokeh.models.annotations import Span, Label\n",
    "from bokeh.plotting import figure\n",
    "output_notebook()\n",
    "\n",
    "# Helper function\n",
    "def get_coords_review(word):\n",
    "    \"\"\"Given a word from `vocab_df_review`, returns tuple with x, y coordinates.\"\"\"\n",
    "    coords = vocab_df_review[vocab_df_review['word'] == word][['x', 'y']]\n",
    "    return list(coords.itertuples(name=None, index=False))[0]\n",
    "\n",
    "# Create plot\n",
    "p = figure(plot_width=700, \n",
    "           plot_height=400,\n",
    "           tools=[HoverTool(tooltips='@word'), BoxZoomTool(), ResetTool()],\n",
    "           title='Book Reviews Vocabulary')\n",
    "\n",
    "# Add vocabulary\n",
    "source = ColumnDataSource(vocab_df_review)\n",
    "p.circle('x', 'y', source=source, size=5, \n",
    "         fill_color='blue', fill_alpha=0.3, \n",
    "         hover_fill_color='yellow')\n",
    "\n",
    "# Add verticle and horizontal lines\n",
    "line_x, line_y = get_coords_review('story')\n",
    "\n",
    "vline = Span(location=line_x, dimension='height', \n",
    "             line_dash='dashed', line_color='red')\n",
    "p.add_layout(vline)\n",
    "\n",
    "hline = Span(location=line_y, dimension='width', \n",
    "             line_dash='dashed', line_color='red')\n",
    "p.add_layout(hline)\n",
    "\n",
    "# Display plot\n",
    "show(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
