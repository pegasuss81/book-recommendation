{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87ce49d5-b5ad-43c5-adab-a142bbd65c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ujson as json\n",
    "import gzip\n",
    "import pandas as pd\n",
    "\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a30f1816-8f02-4106-98a0-4e85a9d24cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import base\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8848645-44f6-45ae-b4ef-5d6d035fb800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "import re\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import spacy\n",
    "\n",
    "import dill\n",
    "\n",
    "from functools import reduce\n",
    "#import time "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e113a6ab-c38b-41bd-aa5e-d13d10f56f8b",
   "metadata": {},
   "source": [
    "## Data Processing for the Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ad6d7f8-f7e7-48f7-bdc2-6edb95ee2896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe for every review\n",
    "df_merge_new_in = pd.read_csv('data/df_merge_with_URL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b271339b-6a05-4136-a22a-9e99977a6f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 5000\n",
    "chunks = [x for x in range(0, df_merge_new_in.shape[0], chunk_size)]\n",
    "\n",
    "df_merge_pivot = pd.concat([df_merge_new_in.iloc[ chunks[i]:chunks[i + 1] - 1 ].pivot_table(index='title', columns='reviewerID', values='overall') for i in range(0, len(chunks) - 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcb81fe8-935a-4eaf-8470-ae71e97ea868",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_pivot.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29e6b06c-018e-45b1-b29f-572c6ef3e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/model_knn.dill\", \"rb\") as f:\n",
    "    model_knn = dill.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8842d0da-ab80-4b0c-b647-c864e8c6f71e",
   "metadata": {},
   "source": [
    "## Preprocessing for Vectorizer + FeatureUnion Using Description & ReviewText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d427db70-138d-4091-a089-138e7914d286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe sorted for each book/title\n",
    "df_merge_review_URL = pd.read_csv('data/df_merge_review_title_with_URL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c935c541-c10a-42c3-8268-7399e76d555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data as a dictionary that can be fed into DictVectorizer\n",
    "class DictEncoder(base.BaseEstimator, base.TransformerMixin):\n",
    "    \n",
    "    def __init__(self, col):\n",
    "        self.col = col\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        def to_dict(l):\n",
    "            try:\n",
    "                return {x: 1 for x in l}\n",
    "            except TypeError:\n",
    "                return {}\n",
    "        \n",
    "        return X[self.col].apply(to_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ed56263-6b96-4d59-a3dc-eb1bfbfe62d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_review_pipe = Pipeline([\n",
    "    ('encoder', DictEncoder('reviewText')),\n",
    "    ('vectorizer', DictVectorizer())\n",
    "])\n",
    "merge_desc_pipe = Pipeline([\n",
    "    ('encoder', DictEncoder('description')),\n",
    "    ('vectorizer', DictVectorizer())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd874d4b-af53-4f59-9c86-05b9424afb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing for Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "793f02dc-fd41-45c5-af11-2c3413786ec7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'average_vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sf/_m3jncf51zgdm38790_vm2pw0000gn/T/ipykernel_2216/1965666810.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/average_vec.dill\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdill\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'average_vec' is not defined"
     ]
    }
   ],
   "source": [
    "# with open(\"data/average_vec.dill\", \"wb\") as f:\n",
    "#     dill.dump(average_vec, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25fd494-cf79-41d0-9203-d9a477beebf8",
   "metadata": {},
   "source": [
    "### Collection of Recommendation Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fe95f21-48aa-4374-8477-9c278fb8d128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommender from user ratings - collaborative filtering. pivot table + NearestNeighbors\n",
    "def book_recommender_collab(string):\n",
    "    \n",
    "    title = df_merge_pivot[df_merge_pivot.index.str.contains(string)].index[0]\n",
    "    \n",
    "    distances, indices = model_knn.kneighbors(df_merge_pivot.loc[title, :].values.reshape(1, -1), n_neighbors=21908)\n",
    "    titles = df_merge_pivot.index[np.array(indices.flatten())]\n",
    "    \n",
    "    return titles, distances.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbb4c0eb-da58-4d89-8e26-2ee0a93dddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "bambi_rec_collab = book_recommender_collab(\"Bambi\")\n",
    "#bambi_rec_collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1a8d472-060a-4deb-97c4-75853bb2e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommender using reviewText and description for each book. vectorizer + FeatureUnion + NearestNeighbors\n",
    "def book_recommender_text_features(w1, w2, string):\n",
    "    \"\"\"\n",
    "    book recommendation system using\n",
    "    w1: weight for review feature\n",
    "    w2: weight for description feature\n",
    "    string: substring of a title\n",
    "    \"\"\"\n",
    "#     union_merge = FeatureUnion([('reviewText', merge_review_pipe),\n",
    "#                       ('description', merge_desc_pipe)],\n",
    "#                     transformer_weights={\n",
    "#             'reviewText': w1,\n",
    "#             'description': w2\n",
    "#         })\n",
    "#     features_merge_review = union_merge.fit_transform(df_merge_review_URL)\n",
    "    \n",
    "#     with open(\"data/features_merge_review.dill\", \"wb\") as f:\n",
    "#         dill.dump(features_merge_review, f)\n",
    "        \n",
    "    with open(\"data/features_merge_review.dill\", \"rb\") as f:\n",
    "        features_merge_review = dill.load(f)\n",
    "        \n",
    "#     union_merge_review_model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "#     union_merge_review_model.fit(features_merge_review)\n",
    "    \n",
    "#     with open(\"data/union_merge_review_model.dill\", \"wb\") as f:\n",
    "#         dill.dump(union_merge_review_model, f)\n",
    "        \n",
    "    with open(\"data/union_merge_review_model.dill\", \"rb\") as f:\n",
    "        union_merge_review_model = dill.load(f)\n",
    "        \n",
    "    index1 = df_merge_review_URL[df_merge_review_URL.title.str.contains(string)].index[0]\n",
    "    title1 = df_merge_review_URL[df_merge_review_URL.title.str.contains(string)]['title'].values[0]\n",
    "    \n",
    "    #distances, indices = union_merge_review_model.kneighbors(features_merge_review[index1], n_neighbors=6)\n",
    "    distances, indices = union_merge_review_model.kneighbors(features_merge_review[index1], n_neighbors=df_merge_review_URL.shape[0])\n",
    "    titles = df_merge_review_URL['title'][df_merge_review_URL.index[np.array(indices.flatten())]].tolist()\n",
    "    #print(titles)\n",
    "    \n",
    "    #return distances, indices, titles\n",
    "    return titles, distances.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e5ac06d-e9a0-48c9-9ce2-612a1efdfcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bambi_rec_vect = book_recommender_text_features(0.2, 1, \"Bambi\")\n",
    "#bambi_rec_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6140bee8-f1de-4f86-b609-9b2fc071db3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommender using Word2Vec model\n",
    "\n",
    "def book_recommender_wv(string):\n",
    "    # finding cosine similarity for the vectors\n",
    "#     cosine_similarities = cosine_similarity(average_vec, average_vec)\n",
    "    \n",
    "#     with open(\"data/cosine_similarities.dill\", \"wb\") as f:\n",
    "#         dill.dump(cosine_similarities, f)\n",
    "        \n",
    "    with open(\"data/cosine_similarities.dill\", \"rb\") as f:\n",
    "        cosine_similarities = dill.load(f)\n",
    "    \n",
    "    #print(type(cosine_similarities))\n",
    "    \n",
    "    #title\n",
    "    #books = df_merge_review_URL[['title']]\n",
    "    #print(books)\n",
    "    #Reverse mapping of the index\n",
    "    indices = pd.Series(df_merge_review_URL.index, index = df_merge_review_URL['title']).drop_duplicates()\n",
    "    #print(indices)\n",
    "    \n",
    "    title = df_merge_review_URL[df_merge_review_URL.title.str.contains(string) == True].index[0]\n",
    "    idx = indices[title]\n",
    "    #print(title, idx) # title == idx?\n",
    "    # sim_scores = list(enumerate(cosine_similarities[idx]))\n",
    "    # sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse = True)\n",
    "    sim_scores = list(enumerate(1-cosine_similarities[idx]))\n",
    "    #print(sim_scores)\n",
    "    ##sim_scores = sorted(sim_scores, key = lambda x: x[1])\n",
    "    #print(sim_scores)\n",
    "    titles = df_merge_review_URL['title'][df_merge_review_URL.index[np.array(indices)]].tolist()\n",
    "    #sim_scores = sim_scores[1:6]\n",
    "    return titles, sim_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a84a93e8-9025-45ef-bdff-ff1397af5511",
   "metadata": {},
   "outputs": [],
   "source": [
    "bambi_rec_wv = book_recommender_wv(\"Bambi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30dcde69-0d74-4434-9931-7d1405fa6c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataframe(rec_tuple):\n",
    "    df = pd.DataFrame(rec_tuple).T\n",
    "    df.columns = [\"title\", \"distance\", \"URL\", \"image\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c14421-13e8-46fa-b07f-baf74fa190e4",
   "metadata": {},
   "source": [
    "## Combined Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5de12e90-c3be-4678-916f-50c8753ad7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_model(w_collab=1.0, w_vect_desc=1.0, w_vect_review=0.2, w_feature_union=1.0, w_wv=1.0, string=\"Bambi\", n_rec=5):\n",
    "    df_collab = to_dataframe(book_recommender_collab(string))\n",
    "    df_vect = to_dataframe(book_recommender_text_features(w_vect_desc, w_vect_review, string))\n",
    "    df_wv = to_dataframe(book_recommender_wv(string))\n",
    "    df_wv['distance'] = df_wv['distance'].str[1]\n",
    "    \n",
    "    df_join = reduce(lambda left, right: pd.merge(left,right,on=['title'],\n",
    "                                            how='outer'), [df_collab, df_vect, df_wv])\n",
    "    df_join.columns = ['title', 'dist_collab', 'dist_vect', 'dist_wv', 'URL', 'image']\n",
    "    \n",
    "    df_join['dist_metric'] = w_collab * df_join['dist_collab'] + w_feature_union * df_join['dist_vect'] \\\n",
    "            + w_wv * df_join['dist_wv']\n",
    "#     df_join.sort_values('dist_metric')[[\"title\", \"dist_metric\", \"URL\", \"image\"]].head(10)\n",
    "    \n",
    "#     # Top 5 book recommendation\n",
    "#     rec = df_join[['title', 'image_url']].iloc[movie_indices]\n",
    "       \n",
    "#     # It reads the top 5 recommend book url and print the images\n",
    "    \n",
    "#     for i in rec['image_url']:\n",
    "#         response = requests.get(i)\n",
    "#         img = Image.open(BytesIO(response.content))\n",
    "#         plt.figure()\n",
    "#         print(plt.imshow(img))\n",
    "    return df_join.sort_values('dist_metric')[[\"title\", \"URL\"]].head(n_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7793519f-e5e4-4327-b997-f540606cdb1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
